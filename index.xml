<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Risks (and Benefits) of Generative AI and Large Language Models</title>
    <link>https://llmrisks.github.io/</link>
    <description>Recent content on Risks (and Benefits) of Generative AI and Large Language Models</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>evans@virginia.edu (David Evans)</managingEditor>
    <webMaster>evans@virginia.edu (David Evans)</webMaster>
    <lastBuildDate>Wed, 23 Aug 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://llmrisks.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Week 9: Interpretability</title>
      <link>https://llmrisks.github.io/week9/</link>
      <pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week9/</guid>
      <description>(see bottom for assigned readings and questions)
Presenting Team: Anshuman Suri, Jacob Christopher, Kasra Lekan, Kaylee Liu, My Dinh
Blogging Team: Hamza Khalid, Liu Zhe, Peng Wang, Sikun Guo, Yinhan He, Zhepei Wei
Monday, 23 October: Interpretability: Overview, Limitations, &amp;amp; Challenges Definition of Interpretability  Interpretability in the context of artificial intelligence (AI) and machine learning refers to the extent to which a model&amp;rsquo;s decisions, predictions, or internal workings can be understood and explained by humans.</description>
    </item>
    
    <item>
      <title>Week 8: Machine Translation</title>
      <link>https://llmrisks.github.io/week8/</link>
      <pubDate>Sun, 22 Oct 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week8/</guid>
      <description>(see bottom for assigned readings and questions)
Machine Translation (Week 8) Presenting Team: Ajwa Shahid, Caroline Gihlstorf, Changhong Yang, Hyeongjin Kim, Sarah Boyce
Blogging Team: Xindi Guo, Mengxuan Hu, Tseganesh Beyene Kebede, Zihan Guan
Monday, 16 Oct: Diving into the History of Machine Translation Let&amp;rsquo;s kick off this topic with an activity that involves translating an English sentence into a language of your choice and subsequently composing pseudocode to describe the process.</description>
    </item>
    
    <item>
      <title>Week 7: GANs and DeepFakes</title>
      <link>https://llmrisks.github.io/week7/</link>
      <pubDate>Mon, 16 Oct 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week7/</guid>
      <description>(see bottom for assigned readings and questions)
Presenting Team: Aparna Kishore, Elena Long, Erzhen Hu, Jingping Wan 
Blogging Team: Haochen Liu, Haolin Liu, Ji Hyun Kim, Stephanie Schoch, Xueren Ge 
Monday, 9 October: Generative Adversarial Networks and DeepFakes Today&#39;s topic is how to utilize generative adversarial networks to create fake images and how to identify the images generated by these models.
 Generative Adversarial Network (GAN) is a revolutionary deep learning framework that pits two neural networks against each other in a creative showdown.</description>
    </item>
    
    <item>
      <title>Week 5: Hallucination</title>
      <link>https://llmrisks.github.io/week5/</link>
      <pubDate>Wed, 04 Oct 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week5/</guid>
      <description>(see bottom for assigned readings and questions)
Hallucination (Week 5) Presenting Team: Liu Zhe, Peng Wang, Sikun Guo, Yinhan He, Zhepei Wei
Blogging Team: Anshuman Suri, Jacob Christopher, Kasra Lekan, Kaylee Liu, My Dinh
Wednesday, September 27th: Intro to Hallucination      People Hallucinate Too         Hallucination Definition  There are three types of hallucinations according to the “Siren&#39;s Song in the AI Ocean” paper:  Input-conflict: This subcategory of hallucinations deviates from user input.</description>
    </item>
    
    <item>
      <title>Week 4: Capabilities of LLMs</title>
      <link>https://llmrisks.github.io/week4/</link>
      <pubDate>Mon, 25 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week4/</guid>
      <description>(see bottom for assigned readings and questions)
Capabilities of LLMs (Week 4) Presenting Team: Xindi Guo, Mengxuan Hu, Tseganesh Beyene Kebede, Zihan Guan
Blogging Team: Ajwa Shahid, Caroline Gihlstorf, Changhong Yang, Hyeongjin Kim, Sarah Boyce
Monday, September 18 Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, Xia Hu. Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. April 2023. https://arxiv.org/abs/2304.13712</description>
    </item>
    
    <item>
      <title>Week 3: Prompting and Bias</title>
      <link>https://llmrisks.github.io/week3/</link>
      <pubDate>Mon, 18 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week3/</guid>
      <description>(see bottom for assigned readings and questions)
Prompt Engineering (Week 3) Presenting Team: Haolin Liu, Xueren Ge, Ji Hyun Kim, Stephanie Schoch 
Blogging Team: Aparna Kishore, Erzhen Hu, Elena Long, Jingping Wan
 (Monday, 09/11/2023) Prompt Engineering  Warm-up questions What is Prompt Engineering? How is prompt-based learning different from traditional supervised learning? In-context learning and different types of prompts What is the difference between prompts and fine-tuning? When is the best to use prompts vs fine-tuning?</description>
    </item>
    
    <item>
      <title>Week 2: Alignment</title>
      <link>https://llmrisks.github.io/week2/</link>
      <pubDate>Mon, 11 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week2/</guid>
      <description>(see bottom for assigned readings and questions)
Table of Contents  (Monday, 09/04/2023) Introduction to Alignment  Introduction to AI Alignment and Failure Cases  Discussion Questions   The Alignment Problem from a Deep Learning Perspective  Group of RL-based methods Group of LLM-based methods Group of Other ML methods     (Wednesday, 09/06/2023) Alignment Challenges and Solutions  Opening Discussion Introduction to Red-Teaming  In-class Activity (5 groups) How to use Red-Teaming?</description>
    </item>
    
    <item>
      <title>Week 1: Introduction</title>
      <link>https://llmrisks.github.io/week1/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/week1/</guid>
      <description>(see bottom for assigned readings and questions)
Attention, Transformers, and BERT Monday, 28 August
Transformers1 are a class of deep learning models that have revolutionized the field of natural language processing (NLP) and various other domains. The concept of transformers originated as an attempt to address the limitations of traditional recurrent neural networks (RNNs) in sequential data processing. Here&amp;rsquo;s an overview of transformers&amp;rsquo; evolution and significance.
Background and Origin RNNs2 were one of the earliest models used for sequence-based tasks in machine learning.</description>
    </item>
    
    <item>
      <title>Github Discussions</title>
      <link>https://llmrisks.github.io/discussions/</link>
      <pubDate>Fri, 25 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/discussions/</guid>
      <description>Everyone should have received an invitation to the github discussions site, and be able to see the posts there and submit your own posts and comments. If you didn&amp;rsquo;t get this invitation, it was probably blocked by the email system. Try visiting:
https://github.com/orgs/llmrisks/invitation
(while logged into the github account you listed on your form).
Once you&amp;rsquo;ve accepted the invitation, you should be able to visit https://github.com/llmrisks/discussions/discussions/2 (the now-finalized discussion post for Week 1), and contribute to the discussions there.</description>
    </item>
    
    <item>
      <title>Class 0: Getting Organized</title>
      <link>https://llmrisks.github.io/class0/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/class0/</guid>
      <description>I&amp;rsquo;ve updated the Schedule and Bi-Weekly Schedule based on the discussions today.
The plan is below:
  Week Lead Team Blogging Team Everyone Else     Two Weeks Before  Come up with idea for the week and planned readings, send to me by 5:29pm on Tuesday (2 weeks - 1 day before)  -  -    Week Before  Post plan and questions in github discussions by no later than 9am Wednesday; prepare for leading meetings   Prepare plan for blogging (how you will divide workload, collaborative tools for taking notes and writing)   Read/do materials and respond to preparation questions in github discussions (by 5:29pm Sunday)    Week of Leading Meetings  Lead interesting, engaging, and illuminating meetings!</description>
    </item>
    
    <item>
      <title>Weekly Schedule</title>
      <link>https://llmrisks.github.io/weeklyschedule/</link>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/weeklyschedule/</guid>
      <description>This is the regular bi-weekly schedule:
  Week Lead Team Blogging Team Everyone Else     Two Weeks Before  Come up with idea for the week and planned readings, send to me by 5:29pm on Tuesday (2 weeks - 1 day before)  -  -    Week Before  Post plan and questions in github discussions by no later than 9am Wednesday; prepare for leading meetings   Prepare plan for blogging (how you will divide workload, collaborative tools for taking notes and writing)   Read/do materials and respond to preparation questions in github discussions (by 5:29pm Sunday)    Week of Leading Meetings  Lead interesting, engaging, and illuminating meetings!</description>
    </item>
    
    <item>
      <title>Readings and Topics</title>
      <link>https://llmrisks.github.io/readings/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/readings/</guid>
      <description>This page collects some potential topics and readings for the seminar.
Introduction (Week 1) Introduction to Large Language Models (from Stanford course)
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. Attention Is All You Need. https://arxiv.org/abs/1706.03762. NeurIPS 2017.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. ACL 2019.
(optional) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever.</description>
    </item>
    
    <item>
      <title>Schedule</title>
      <link>https://llmrisks.github.io/schedule/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/schedule/</guid>
      <description>The schedule details will be filled in as the semester progresses (and future weeks are subject to change, but as much as is known is documented here).
See Weekly Schedule for the bi-weekly expectations for each team.
  Week Lead Team Blog Team Topic     0: 23 Aug Dave Starting the Seminar   1: 28/30 Aug 14     2: 4/6 Sep 25     3: 11/13 Sep 36     4: 18/20 Sep 41     5: 25/27 Sep 52     6: 4 Oct TBD (2 Oct is Fall Classes Break)    7: 9/11 Oct 63     8: 16/18 Oct 14     9: 23/25 Oct 25     10: 30 Oct/1 Nov 36     11: 6/8 Nov 41     14: 13/15 Nov 5 2     15: 20 Nov TBD (22 Nov is Thanksgiving Break)   16: 27/29 Nov 6 3     17: 4 Dec TBD (Last meeting is 4 December)    Leading Team Schedule As the leading team, your job is to select a worthwhile topic, decide on a reading assignment (which can include things other than reading and is not limited to typical research papers) for the class, write questions that the class should write responses to in preparation for the discussion, and lead an interesting, engaging, and illuminating class!</description>
    </item>
    
    <item>
      <title>Updates</title>
      <link>https://llmrisks.github.io/updates/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/updates/</guid>
      <description>Some materials have been posted on the course site:
 Syllabus Schedule (you will find out which team you are on at the first class Wednesday) Readings and Topics (a start on a list of some potential readings and topics that we might want to cover)   
Dall-E Prompt: &#34;comic style drawing of a phd seminar on AI&#34;  </description>
    </item>
    
    <item>
      <title>Welcome Survey</title>
      <link>https://llmrisks.github.io/survey/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/survey/</guid>
      <description>Please submit this welcome survey before 8:59pm on Monday, August 21:
 https://forms.gle/dxhFmJH7WRs32s1ZA
 Your answers won&amp;rsquo;t be shared publicly, but I will use the responses to the survey to plan the seminar, including forming teams, and may share some aggregate and anonymized results and anonymized quotes from the surveys.</description>
    </item>
    
    <item>
      <title>Welcome to the LLM Risks Seminar</title>
      <link>https://llmrisks.github.io/welcome/</link>
      <pubDate>Fri, 26 May 2023 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/welcome/</guid>
      <description>Full Transcript
 Seminar Plan The actual seminar won&amp;rsquo;t be fully planned by GPT-4, but more information on it won&amp;rsquo;t be available until later.
I&amp;rsquo;m expecting the structure and format to that combines aspects of this seminar on adversarial machine learning and this course on computing ethics, but with a topic focused on learning as much as we can about the potential for both good and harm from generative AI (including large language models) and things we can do (mostly technically, but including policy) to mitigate the harms.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://llmrisks.github.io/syllabus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/syllabus/</guid>
      <description>Syllabus cs6501: Risks and Benefits of Generative AI and LLMs University of Virginia, Fall 2023
Meetings: Mondays and Wednesdays, 9:30-10:45am in Rice 340
Course Objective. This seminar will focus on understanding the potential risks and benefits of advances in Generative Artificial Intelligence and Large Language Models. This is a research-focused seminar that will expect students to read papers and lead discussions.
Expected Background: Students are not required to have prior background in machine learing or security, but will be expected to learn whatever background they need on these topics mostly on their own.</description>
    </item>
    
    <item>
      <title>Blogging Mechanics</title>
      <link>https://llmrisks.github.io/blogging/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>evans@virginia.edu (David Evans)</author>
      <guid>https://llmrisks.github.io/blogging/</guid>
      <description>Here are some suggestions for how to create the class blog posts for your assigned classes.
I believe each team has at least a few members with enough experience using git and web contruction tools that following these instructions won&amp;rsquo;t be a big burden, but if you have other ways you want to build your blog page for a topic let me know and we can discuss alternative options.
  Install Hugo.</description>
    </item>
    
  </channel>
</rss>